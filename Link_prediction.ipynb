{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow.contrib.eager as tfe\n",
    "from tensorflow import keras\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'r') as content:\n",
    "    lines = content.readlines()\n",
    "    \n",
    "source_list = []\n",
    "sink_list = []\n",
    "user_set = set()\n",
    "for line in lines:\n",
    "    nodes = line.strip().split('\\t')\n",
    "    source_list.append(nodes[0])\n",
    "    for user in nodes:\n",
    "        user_set.add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeList = []\n",
    "for line in lines:\n",
    "    nodes = line.strip()\n",
    "    edgeList.append(nodes)\n",
    "\n",
    "FG = nx.parse_adjlist(edgeList, nodetype=str, delimiter='\\t')\n",
    "edges = set(FG.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle edges\n",
    "import random\n",
    "\n",
    "valid_edges = random.sample(edges,10000)\n",
    "fake_source = random.sample(user_set, 1000)\n",
    "fake_edges = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in fake_source:\n",
    "    sink = random.sample(user_set, 1)\n",
    "    if (source, sink[0]) not in edges:\n",
    "        fake_edges.append((source, sink[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalEdges = []\n",
    "for u, v in valid_edges:\n",
    "    totalEdges.append((u,v,1))\n",
    "for u, v in fake_edges:\n",
    "    totalEdges.append((u,v,0))\n",
    "    \n",
    "random.shuffle(totalEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test-public.txt') as fc:\n",
    "    pred = fc.readlines()\n",
    "    \n",
    "predEdge = []\n",
    "for line in pred[1:]:\n",
    "    a,b,c = line.strip().split('\\t')\n",
    "    p = (b,c)\n",
    "    predEdge.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def salton(u, v):\n",
    "    common_neighbors = len(list(nx.common_neighbors(FG, u, v)))\n",
    "    a = FG.degree(u)\n",
    "    b = FG.degree(v)\n",
    "    salton = common_neighbors / math.sqrt(a * b)\n",
    "    return salton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_name = [(s,d) for s,d,l in totalEdges]\n",
    "Y_train = np.array([l for s, d, l in totalEdges])\n",
    "X_train = np.empty((len(Y_train), 6))\n",
    "\n",
    "for i in range(len(edge_name)):\n",
    "    X_train[i][0] = len(list(nx.common_neighbors(FG, edge_name[i][0], edge_name[i][1])))\n",
    "\n",
    "feature_jac = nx.jaccard_coefficient(FG, edge_name)\n",
    "for u,v,p in feature_jac:\n",
    "    i = edge_name.index((u,v))\n",
    "    X_train[i][1] = p\n",
    "\n",
    "feature_RAI = nx.resource_allocation_index(FG, edge_name)\n",
    "for u,v,p in feature_RAI:\n",
    "    i = edge_name.index((u,v))\n",
    "    X_train[i][2] = p\n",
    "\n",
    "feature_AAI = nx.adamic_adar_index(FG, edge_name)\n",
    "for u,v,p in feature_AAI:\n",
    "    i = edge_name.index((u,v))\n",
    "    X_train[i][3] = p\n",
    "\n",
    "feature_pre = nx.preferential_attachment(FG, edge_name)\n",
    "for u,v,p in feature_pre:\n",
    "    i = edge_name.index((u,v))\n",
    "    X_train[i][4] = p\n",
    "    \n",
    "for edge in edge_name:\n",
    "    i = edge_name.index((edge[0],edge[1]))\n",
    "    X_train[i][5] = salton(edge[0],edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testF = np.empty((len(predEdge), 6))\n",
    "\n",
    "for i in range(len(predEdge)):\n",
    "    testF[i][0] = len(list(nx.common_neighbors(FG, predEdge[i][0], predEdge[i][1])))\n",
    "\n",
    "test_pre1 = nx.jaccard_coefficient(FG, predEdge)\n",
    "for u,v,p in test_pre1:\n",
    "    i = predEdge.index((u,v))\n",
    "    testF[i][1] = p\n",
    "\n",
    "test_pre2 = nx.resource_allocation_index(FG, predEdge)\n",
    "for u,v,p in test_pre2:\n",
    "    i = predEdge.index((u,v))\n",
    "    testF[i][2] = p\n",
    "\n",
    "test_pre3 = nx.adamic_adar_index(FG, predEdge)\n",
    "for u,v,p in test_pre3:\n",
    "    i = predEdge.index((u,v))\n",
    "    testF[i][3] = p\n",
    "\n",
    "test_pre4 = nx.preferential_attachment(FG, predEdge)\n",
    "for u,v,p in test_pre4:\n",
    "    i = predEdge.index((u,v))\n",
    "    testF[i][4] = p\n",
    "    \n",
    "for edge in predEdge:\n",
    "    i = predEdge.index((edge[0],edge[1]))\n",
    "    testF[i][5] = salton(edge[0],edge[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_collection = pd.read_pickle(\"1W1k.pkl\")\n",
    "test_collection = pd.read_pickle(\"test_6F.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"resource_allocation_index\",\"salton\",\"common_neighbors\"]\n",
    "X_train = train_collection[features]\n",
    "Y_train = train_collection[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_collection[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes = [10, 10, 5], alpha = 5,random_state = 0, solver='lbfgs', verbose=0, activation='logistic')\n",
    "clf.fit(X_train_scaled, Y_train)\n",
    "test_proba = clf.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('test7.csv', 'w', newline='', encoding='utf-8') as csv_fp:\n",
    "    csv_fp_writer = csv.writer(csv_fp, delimiter=',')\n",
    "    csv_fp_writer.writerow([\"Id\", \"Prediction\"])\n",
    "    csv_fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_proba.shape[0]):\n",
    "    with open('test7.csv', 'a', newline='') as csv_fp2:\n",
    "        csv_fp_writer2 = csv.writer(csv_fp2)\n",
    "        csv_fp_writer2.writerow([i+1, test_proba[i]])\n",
    "        \n",
    "csv_fp2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
